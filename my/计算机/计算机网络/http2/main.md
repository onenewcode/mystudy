# web优化
## HTTP/1的问题
### 1. 队头阻塞
设想这样一个网站，它把所有图片放在单个特定域名下。HTTP/1 并未提供机制来同时请求这些资源。如果仅仅使用一个连接，它需要发起请求、等待响应，之后才能发起下一个请求。
h1 有个特性叫管道化（pipelining），允许一次发送一组请求，但是只能按照发送顺序依次接收响应。而且，管道化备受互操作性和部署的各种问题的困扰，基本没有实用价值。在请求应答过程中，如果出现任何状况，剩下所有的工作都会被阻塞在那次请求应答之后。这就是“队头阻塞”，它会阻碍网络传输和 Web 页面渲染，直至失去响应。为了防止这种问题，现代浏览器会针对单个域名开启 6 个连接，通过各个连接分别发送请求。它实现了某种程度上的行，但是每个连接仍会受到“队头阻塞”的影响。另外，这也没有高效利用有限的设备资源；下一节会解释原因。
### 2. 低效的TCP利用
传输控制协议（TCP）的设计思路是：对假设情况很保守，并能够公平对待同一网络的不同流量的应用。它的避免拥塞机制被设计成即使在最差的网络状况下仍能起作用，并且如果有需求冲突也保证相对公平。这是它取得成功的原因之一。它的成功并不是因为传输
数据最快，而是因为它是最可靠的协议之一，涉及的核心概念就是拥塞窗口（congestion window）。拥塞窗口是指，在接收方确认数据包之前，发送方可以发出的 TCP 包的数量。例如，如果拥塞窗口指定为 1，那么发送方发出 1 个数据包之后，只有接收方确认了那个包，才能发送下一个。
TCP 有个概念叫慢启动（Slow Start），它用来探索当前连接对应拥塞窗口的合适大小。慢启动的设计目标是为了让新连接搞清楚
当前网络状况，避免给已经拥堵的网络继续添乱。它允许发送者在收到每个确认回复后额外发送 1 个未确认包。这意味着新连接在收到 1 个确认回复之后，可以发送 2 个数据包；在收到 2 个确认回复之后，可以发 4 个；以此类推。这种几何级数增长很快就会到达协议规定的发包数上限，这时候连接将进入拥塞避免阶段，如图 3-4 所示
<img src="img\屏幕截图 2023-05-16 162638.png">

### 3. 臃肿的消息首部
虽然 h1 提供了压缩被请求内容的机制，但是消息首部却无法压缩。消息首部可不能忽略，尽管它比响应资源小很多，但它可能占据请求的绝大部分（有时候可能是全部）。如果算上 cookie，有个几千字节就很正常了。据 HTTP 历史存档记录，2016 年末，请求首部一般集中在 460 字节左右。对于包含 140 个资源的普通 Web 页面，意味着它在发起的所有请求中大约占 63KB。想想之前关于 TCP 拥塞窗口管理的讨论，发送该页面相关的所有请求可能需要 3~4 轮往返，因此网络延迟的损耗会被迅速放大。此外，上行带宽通常会受到网络限制，尤其是在移动网络环境中，于是拥塞窗口机制根本来不及起作用，导致更多的请求和响应。消息首部压缩的缺失也容易导致客户端到达带宽上限，对于低带宽或高拥堵的链路尤其如此。“体育馆效应”（Stadium Effect）就是一个经典例子。如果成千上万人同一时间出现在同一地点（例如重大体育赛事），会迅速耗尽无线蜂窝网络带宽。这时候，如果能压缩请求首部，把请求变得更小，就能够缓解带宽压力，降低系统的总负载

### 4. 受限的优先级设置
如果浏览器针对指定域名开启了多个 socket（每个都会受队头阻塞问题的困扰），开始请求资源，这时候浏览器能指定优先级的方式是有限的：要么发起请求，要么不发起。然而Web 页面上某些资源会比另一些更重要，这必然会加重资源的排队效应。这是因为浏览器为了先请求优先级高的资源，会推迟请求其他资源。但是优先级高的资源获取之后，在处理的过程中，浏览器并不会发起新的资源请求，所以服务器无法利用这段时间发送优先级低的资源，总的页面下载时间因此延长了。还会出现这样的情况：一个高优先级资源
被浏览器发现，但是受制于浏览器处理的方式，它被排在了一个正在获取的低优先级资源
之后。
### 5. 第三方资源
虽然第三方资源不是 HTTP/1 特有的问题，但鉴于它日益增长的性能问题，我们也把它列在这里。如今的 Web 页面上请求的很多资源完全独立于站点服务器的控制，我们称这些为第三方资源。现代 Web 页面加载时长中往往有一半消耗在第三方资源上。虽然有很多技巧能把第三方资源对页面性能的影响降到最低，但是很多第三方资源都不在 Web 开发者的控制范围内，所以很可能其中有些资源的性能很差，会延迟甚至阻塞页面渲染。任何关于 Web 性能的讨论，只要没有提到第三方资源引起的问题，都不算完整。
## 优化
### 1 DNS查询优化
• 限制不同域名的数量。当然，这通常不是你能控制的；但是如果准备迁移到 HTTP/2，域名数量对性能的相对影响会只增不减。
• 保证低限度的解析延迟。了解你的 DNS 服务基础设施的结构，然后从你的最终用户分布的所有地域定期监控解析时间（你能通过虚拟或真实用户的监控做到）。如果你要依赖外部供应商，一定要谨慎选择，因为各家的服务质量参差不齐。
• 在主体页面 HTML 或响应中利用 DNS 预取指令 。这样，在下载并处理主体页面 HTML的同时，预取指令就能开始解析页面上指定的域名。
### 2 优化TCP连接
• 利用 preconnect 指令 ，连接在使用之前就已经建立好了，这样处理流程的关键路径上就不必考虑连接时间了。例如：
<link rel="preconnect" href="//fonts.example.com" crossorigin>
• 尽早终止并响应。借助 CDN，在距离请求用户很近的边缘端点上，请求就可以获得响应，所以可以终止连接，大幅减少建立新连接的通信延迟。
• 实施最新的 TLS 最佳实践 6 来优化 HTTPS

### 3 避免重定向
重定向通常触发与额外域名建立连接。在无线网络中（想想手机用户），一次额外的重定向可能把延迟增加数百毫秒，这不利于用户体验，并最终会影响到网站上的业务。简单的解决方案就是彻底消灭重定向，因为对于重定向的使用往往并没有合理原因。如果它们不
能被直接消灭，你还有两个选择：
• 利用 CDN 代替客户端在云端实现重定向；
• 如果是同一域名的重定向，使用 Web 服务器上的 rewrite 规则，避免重定向
### 4 客户端缓存
• 所谓的纯静态内容，例如图片或带版本的数据，可以在客户端永久缓存。尽管如此，我们也要记住，即便 TTL 被设置得很长，比如一个月，它还是会因为缓存提早回收或清理而过期，这时客户端可能不得不从源头再次获取。因此真实的 TTL（效果）最终取决于设备特性（尤其是可用磁盘缓存空间）和最终用户的浏览习惯 / 历史记录。
• CSS/JS 和个性化资源，缓存时间大约是会话（交互）平均时间的两倍。这段时间足够长，保证大多数用户在浏览网站时能够从本地拉取资源；同时也足够短，几乎能保证下次会话时从网络上拉取最新内容。
• 其他类型的资源，理想的 TTL 值会各有不同；这取决于你对特定资源能够容忍的旧数据的极限。所以，你必须结合自身需求来判断最佳值
### 5 网络边缘缓存
因为所有用户都能从云端的共享缓存受益，所以网络边缘的缓存提供了更快的访问速度，也为网站服务基础设施分担了很大一部分流量。
如果一份资源需要缓存，它必须满足：
• 在多用户间可共享，并且
• 能够接受一定程度的旧数据
### 6 条件缓存
• 在请求中包含 HTTP 首部 Last-Modified-Since。仅当最新内容在首部中指定的日期之后被更新过，服务器才返回完整内容；否则只返回 304 响应码，并在响应首部中附带上新的时间戳 Date 字段。
• 在请求体中包含实体校验码，或者叫 ETag；它唯一标识所请求的资源。ETag 由服务器
提供，内嵌于资源的响应首部中。服务器会比较当前 ETag 与请求首部中收到的 ETag，如果一致，就只返回 304 响应码；否则返回完整内容。
### 7 压缩和代码极简化
### 8 避免阻塞CSS/JSS
• 定期校验这些资源的使用情况。随着时间的变迁，Web 页面可能会持续下载一些不再需要的 JS；这时候，最快速有效的解决办法就是去掉它。
• 如果 JS 执行顺序无关紧要，并且必须在 onload 事件触发之前运行，那么可以设置async 属性 只需做到下载 JS 与解析 HTML 并 行， 就 能 极 大 地 提 升 整 体 用 户 体 验。 请 慎 用
document.write 指令，因为很可能中断页面执行，所以需要仔细测试。
• 如果 JS 执行顺序很重要，并且你也能承受脚本在 DOM 加载完之后运行，那么请使用defer 属性。

• 对不会影响到页面初次展示的 JS 脚本，必须在 onload 事件触发之后请求（处理）它。

• 如果你不想延迟主页面的 onload 事件，可以考虑通过 iframe 获取 JS，因为它的处理独立于主页面。但是，通过 iframe 下载的 JS 访问不了主页面上的元素。
### 9 图片优化
• 图片元信息，例如题材地理位置信息、时间戳、尺寸和像素信息，通常包含在二进制数据里，应该在发送给客户端之前去掉（务必保留版权和色彩描述信息）。这种无损处理能够在图片生成时完成。对于 PNG 图片，一般会节省大概 10% 的空间。
• 图片过载（image overloading）是指，图片最终被浏览器自动缩小，要么因为原始尺寸超过了浏览器可视区中的占位大小，要么因为像素超过设备的显示能力。这不仅浪费带宽，消耗的 CPU 资源也很可观，这些计算资源有时在手持设备上相当宝贵。
## 反模式
### 1. 生成精灵图和资源合并/内联
精灵图（spriting）是指把很多小图片拼合成一张大图，这样只需发起一个请求就可以覆盖
多个图片元素。
### 2. 域名拆分
域名拆分（sharding）是为了利用浏览器针对每个域名开启多个连接的能力来并行下载资源。
### 3. 禁用cookie的域名
在 HTTP/1 下，请求和响应首部从不会被压缩。随着时间推移，首部大小已经增长了，超过单个 TCP 数据包（约 1.5KB）的 cookie 可以说司空见惯。因此，在内容源和客户端之间来回传输首部信息的开销可能造成明显的延迟。因此，对图片之类不依赖于 cookie 的资源，设置禁用 cookie 的域名是个合理的建议
# http/2协议
## HTTP/2分层
HTTP/2 大致可以分为两部分：分帧层，即 h2 多路复用能力的核心部分；数据或 http 层

**二进制协议**
h2 的分帧层是基于帧的二进制协议。这方便了机器解析，但是肉眼识别起来比较困难。

**首部压缩**
仅仅使用二进制协议似乎还不够，h2 的首部还会被深度压缩。这将显著减少传输中的冗余字节。
**多路复用**
在你喜爱的调试工具里查看基于 h2 传输的连接的时候，你会发现请求和响应交织在一起。
**加密传输**
最重要的是，线上传输的绝大部分数据是加密过的，所以在中途读取会更加困难
## 　连接
连接是所有 HTTP/2 会话的基础元素，其定义是客户端初始化的一个 TCP/IP socket，客户端是指发送 HTTP 请求的实体。这和 h1 是一样的，不过与完全无状态的 h1 不同的是，h2 把它所承载的帧（frame）和流（stream）共同依赖的连接层元素捆绑在一起，其中既包含连接层设置也包含首部表（稍后有对两者更详细的描述）。也就是说，与之前的 HTTP 版本不同，每个 h2 连接都有一定的开销。之所以这么设计，是考虑到收益远远超过其开销
## 　帧
HTTP/2 是基于帧（frame）的协议。采用分帧是为了将重要信息都封装起来，让协议的解析方可以轻松阅读、解析并还原信息。
h1 不是基于帧的，而是以
文本分隔。 看看下面的简单例子：
```
GET / HTTP/1.1 <crlf>
注 3：因为这意味着不会有 2.1、2.2 之类的版本。——译者注
36 ｜ 第 5 章
Host: www.example.com <crlf> 
Connection: keep-alive <crlf> 
Accept: text/html,application/xhtml+xml,application/xml;q=0.9... <crlf> 
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4)... <crlf> 
Accept-Encoding: gzip, deflate, sdch <crlf> 
Accept-Language: en-US,en;q=0.8 <crlf> 
Cookie: pfy_cbc_lb=p-browse-w; customerZipCode=99912|N; ltc=%20;...<crlf> 
<crlf>
```
• 一次只能处理一个请求或响应，完成之前不能停止解析。
• 无法预判解析需要多少内存。这会带来一系列问题：你要把一行读到多大的缓冲区里；如果行太长会发生什么；应该增加并重新分配内存，还是返回 400 错误。为了解决这些问题，保持内存处理的效率和速度可不简单

<img src="img\屏幕截图 2023-05-16 171733.png">

|名称|  长度|  描述|
|---------------|----------------------|-----------------------------|
|Length| 3 字节| 表示帧负载的长度（取值范围为 214~224-1 字节）。 请注意，214 字节是默认的最大帧大小，如果需要更大的帧，必须在 SETTINGS 帧中设置|
|Type |1 字节 |当前帧类型|
|Flags | 1 字节 |具体帧类型的标识|
|R |1 位 |保留位，不要设置，否则可能带来严重后果|
|Stream Identifier| 31 位 |每个流的唯一 ID|
|Frame Payload| 长度可变 |真实的帧内容，长度是在 Length 字段中设置的|



|名称 |ID| 描述|
|---------|----------|--------------|
|DATA |0x0 |传输流的核心内容|
HEADERS |0x1| 包含 HTTP 首部，和可选的优先级参数|
|PRIORITY |0x2| 指示或者更改流的优先级和依赖|
|RST_STREAM| 0x3 允许一端停止流（通常由于错误导致的）
|SETTINGS 0x4 协商连接级参数|
|PUSH_PROMISE |0x5 |提示客户端，服务器要推送些东西|
|PING| 0x6| 测试连接可用性和往返时延（RTT）|
|GOAWAY |0x7 |告诉另一端，当前端已结束|
|WINDOW_UPDATE| 0x8| 协商一端将要接收多少字节（用于流量控制）|
|CONTINUATION| 0x9| 用以扩展 HEADER 数据块|

## 　流
HTTP/2 规范对流（stream）的定义是：“HTTP/2 连接上独立的、双向的帧序列交换。”
### 消息
一切都是header 
h1 把消息分成两部分：请求 / 状态行；首部。h2 取消了这种区分，并把这些行变成了
魔法伪首部。举个例子，HTTP/1.1 的请求和响应可能是这样的：
```
GET / HTTP/1.1 
Host: www.example.com 
User-agent: Next-Great-h2-browser-1.0.0 
Accept-Encoding: compress, gzip 
HTTP/1.1 200 OK 
Content-type: text/plain 
Content-length: 2 
```

在 HTTP/2 中，它等价于：
```
:scheme: https 
:method: GET 
:path: / 
:authority: www.example.com 
User-agent: Next-Great-h2-browser-1.0.0 
Accept-Encoding: compress, gzip 
:status: 200 
content-type: text/plain
```
### 流量控制
h2 提供了客户端调整传输速度的能力。（并且，由于在 h2 中，
一切几乎都是对称的，服务端也可以调整传输的速度。）WINDOW_UPDATE 帧用来指示流量控制信息。每个帧告诉对方，发送方想要接收多少字节。当一端接收并消费被发送的数据时，它将发出一个 WINDOW_UPDATE 帧以指示其更新后的处理字节的能力。（许多

客户端有很多理由使用流量控制。一个很现实的原因可能是，确保某个流不会阻塞其他流。也可能客户端可用的带宽和内存比较有限，强制数据以可处理的分块来加载反而可以提升效率。尽管流量控制不能关闭，把窗口最大值设定为设置 231-1 就等效于禁用它，至少对小于 2GB 的文件来说是如此。另一个需要注意的是中间代理。通常情况下，网络内容通过代理或者 CDN 来传输，也许它们就是传输的起点或终点。由于代理两端的吞吐能力可能不同，有了流量控制，代理的两端就可以密切同步，把代理的压力降到最低
### 优先级
流的最后一个重要特性是依赖关系。
有了 h2，客户端就可以一次发出所有资源的请求，服务端也可以立即着手处理这些请求。
h2 通过流的依赖关系来解决这个问题。通过 HEADERS 帧和 PRIORITY 帧，客户端可以
明确地和服务端沟通它需要什么，以及它需要这些资源的顺序。这是通过声明依赖关系树和树里的相对权重实现的。
• 依赖关系为客户端提供了一种能力，通过指明某些对象对另一些对象有依赖，告知服务器这些对象应该优先传输。
• 权重让客户端告诉服务器如何确定具有共同依赖关系的对象的优先级
## 服务端推送
提升单个对象性能的最佳方式，就是在它被用到之前就放到浏览器的缓存里面。这正是HTTP/2 的服务端推送的目的。推送使服务器能够主动将对象发给客户端，这可能是因为它知道客户端不久将用到该对象。如
### 　推送对象
如果服务器决定要推送一个对象（RFC 中称为“推送响应”），会构造一个 PUSH_PROMISE 帧。这个帧有很多重要属性，列举如下。
• PUSH_PROMISE 帧首部中的流 ID 用来响应相关联的请求。推送的响应一定会对应到客户端已发送的某个请求。如果浏览器请求一个主体 HTML 页面，如果要推送此页面使用的某个 JavaScript 对象，服务器将使用请求对应的流 ID 构造 PUSH_PROMISE 帧。
• PUSH_PROMISE 帧的首部块与客户端请求推送对象时发送的首部块是相似的。所以客户端有办法放心检查将要发送的请求。
• 被发送的对象必须确保是可缓存的。
• :method 首部的值必须确保安全。安全的方法就是幂等的那些方法，这是一种不改变任何状态的好办法。例如，GET 请求被认为是幂等的，因为它通常只是获取对象，而POST 请求被认为是非幂等的，因为它可能会改变服务器端的状态。
• 理想情况下，PUSH_PROMISE 帧应该更早发送，应当早于客户端接收到可能承载着推送对象的 DATA 帧。假设服务器要在发送 PUSH_PROMISE 之前发送完整的 HTML，那客户端可能在接收到 PUSH_PROMISE 之前已经发出了对这个资源的请求。h2 足够健壮，可以优雅地解决这类问题，但还是会有些浪费。
• PUSH_PROMISE 帧会指示将要发送的响应所使用的流 ID。
### 选择要推送的资源
• 资源已经在浏览器缓存中的概率
• 从客户端看来，这些资源的优先级（参见 5.4.3 节）
• 可用的带宽，以及其他类似的会影响客户端接收推送的资源
## 　首部压缩

## 线上传输
```
:authority: www.akamai.com 
:method: GET 
:path: / 
:scheme: https 
accept: text/html,application/xhtml+xml,... 
accept-language: en-US,en;q=0.8 
cookie: sidebar_collapsed=0; _mkto_trk=... 
upgrade-insecure-requests: 1 
user-agent: Mozilla/5.0 (Macintosh;...
```
# HTTP/2性能
第一，协议的具体实现很重要；第二，并非所有请求在任何情况下都会从 HTTP/2 受益
## 　延迟

## 丢包


## 服务端推送
尽管如此，推送也会浪费带宽，这是因为服务端可能试图推送那些在客户端已经缓存的资源，导致客户端收到并不需要的数据。客户端确实可以发送 RST_STREAM 帧来拒绝服务器的 PUSH_PROMISE帧，但是 RST_STREAM 并不会即刻到达，所以服务器还是会发送一些多余的信息
## 首字节时间
• 窗口大小调节
• 依赖树构建
• 维持首部信息的静态 / 动态表
• 压缩 / 解压缩首部
• 优先级调整（h2 允许客户端多次调整单一请求的优先级）
• 预先推送客户端尚未请求的数据流
## 　第三方资源
•  第三方请求往往通过不同域名发送；由于浏览器需要解析 DNS、建立 TCP 连接、协商
TLS，这将严重影响性能。
• 因为第三方资源在不同域名下，所以请求不能从服务端推送、资源依赖、请求优先级h2 特性中受益。这些特性仅是为请求相同域名下的资源设计的。
• 你无法控制第三方资源的性能，也无法决定它们是否会通过 h2 传输
## 现实情况中的性能
**测试地点**
分散在各处的测试地点（美国东海岸、美国西海岸以及欧洲）。
**浏览器**
Chrome 与 Firefox（选择它们是因为可以很容易地禁用 h2，允许 A/B 测试）。
**连接方式**
模拟的网络连接（有线连接和信号强的 3G 网络）。
**测试次数**
每个测试运行 9 次（为了得到更好的平均值）。
# HTTP/2 实现

## 　服务器、代理以及缓存
**Web服务器**
通常所说的提供静态和动态内容服务的程序。
**代理/缓存**
一般处在服务器和最终用户之间，可以提供缓存以减轻服务器负载，或进行额外加工，或两者皆有之。许多代理也能扮演 Web 服务器的角色

## 内容分发网络
内容分发网络（CDN）是反向代理服务器的全球性分布式网络，它部署在多个数据中心。CDN 的目标是通过缩短与最终用户的距离来减少请求往返次数，
# HTTP/2调试
## 浏览器开发者工具
