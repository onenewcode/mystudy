# 模型评估与选择
## 经验误差与过拟合
有多种因素可能导致过拟合，其中最常见的情况是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由于学习能力低下而造成的
## 评估方法
### 留出法
"留出法" (hold-out) 直接将数据集 划分为两个互斥的集合?其中一个集合作为训练集 ，另一个作为测试集 D=BUT T= 正~.在 上训
练出模型后，用 来评估其测试误差，作为对泛化误差的估计
### 交叉验证法
"交叉验证法" (cross alidation) 将数据 分为 个大小相似的
互斥子集， = D1 D2υ... U Dk, Di n Dj = ø (í 每个子集
尽可 保持数据分布的 致性，即从 通过分层采样得到. 后，每次用
k-1 子集的并集作为训练集?余 的那个子集作 试集;
### 自助法
"自助法" (bootstrapping) 它直接以自助采样(bootstrap sampling) 为基础. 给定包含m个样本的数据集 我们对它进行采样产生数据集 D': 每次随机从 中挑选一个样本 将其拷贝放入 D'， 然后再将该样本放回初始数据集 中，使得该样本在下次采样时仍有可能被采到;这个过程重复执行 次后?我们就得到了包含m个样本的数据集 D'，
### 调参与最终模型
## 性能度量

# 线性模型

# 决策树
决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的"分而治之" (divide-and-conquer) 策略
# 划分选择
### 信息增益
"信息熵" (information entropy) 是度量样本集合纯度最常用的一种指标.假定当前样本集合 中第 类样本所占的比例为 Pk (k = 1, 2,. . . , 、|Y|) ，则的信息娟定义为IYI Ent(D) 值为的值小，则的纯度越高.
## 剪枝处理
剪枝(pruning) 是决策树学习算法对付"过拟合"的主要手段
## 连续与缺失值
### 连续值处理
由于连续属性的可取值数目不再有限，不能直接根据连续属性的
取值来对结 进行划分.此 连续属性离散化技术可派上用场 最简单的策略是采用二分法对连续属性进行处理。

# 神经网络
## 神经元模型

## 感知机与多层网络

## 误差逆传播算法